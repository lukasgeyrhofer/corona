{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# statistics\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = [15,12]\n",
    "\n",
    "# own data wrappers\n",
    "from imp import reload\n",
    "import measureclass as mc; reload(mc);\n",
    "import coronadataclass as cdc; reload(cdc);\n",
    "\n",
    "np.seterr(divide = 'ignore');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into datawrapper classes\n",
    "measure_data = mc.COVID19_measures(download_data = False, measure_level = 2, only_first_dates = True, expand_measure_names = True)\n",
    "jhu_data     = cdc.CoronaData(download_data = False)\n",
    "\n",
    "# remove and rename countries to match the JFU database and the measures database\n",
    "measure_data.RemoveCountry('Diamond Princess')\n",
    "measure_data.RenameCountry('France (metropole)', 'France')\n",
    "measure_data.RenameCountry('South Korea', 'Korea, South')\n",
    "measure_data.RenameCountry('Czech Republic', 'Czechia')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def date2vector(implementdate, start = '22/1/20', end = None, shiftdays = 0):\n",
    "    # generate vector of 0s and 1s when measure is implemented or not\n",
    "    starttime     = datetime.datetime.strptime(start,         '%d/%m/%y')\n",
    "    if end is None:\n",
    "        endtime   = datetime.datetime.today()\n",
    "    else:\n",
    "        endtime   = datetime.datetime.strptime(end,           '%d/%m/%y')\n",
    "    implementtime = datetime.datetime.strptime(implementdate, '%d/%m/%Y')\n",
    "    \n",
    "    totaldays   = (endtime       - starttime).days\n",
    "    measuredays = (implementtime - starttime).days\n",
    "    \n",
    "    vec         = np.zeros(totaldays)\n",
    "    vec[min(measuredays+shiftdays,len(vec)-1):] = 1\n",
    "    \n",
    "    return vec\n",
    "\n",
    "\n",
    "def ConvertDateFormat(date):\n",
    "    m,d,y = date.split('/')\n",
    "    return '{:02d}/{:02d}/{:02d}'.format(int(d),int(m),int(y))\n",
    "\n",
    "\n",
    "def CleanUpMeasureName(measurename):\n",
    "    # regression model formula can't contain special characters\n",
    "    return ''.join([mn.capitalize() for mn in measurename.replace(',','').replace('-','').replace('/','').split(' ')])\n",
    "\n",
    "\n",
    "def GetMeasureIDs(countrylist = None, measure_level = 2, mincount = None, extend_measure_names = False):\n",
    "    if countrylist is None:\n",
    "        countrylist = measure_data.countrylist # use ALL countries\n",
    "    \n",
    "    measurelist = {}\n",
    "    \n",
    "    # get all restrictions from countries\n",
    "    for country in countrylist:\n",
    "        country_measures = measure_data.CountryData(country, measure_level = 2, extend_measure_names = extend_measure_names)\n",
    "        for measurename, initialdata in country_measures.items():\n",
    "            if not measurename in measurelist.keys():\n",
    "                measurelist[measurename] = 0\n",
    "            measurelist[measurename] += 1\n",
    "    \n",
    "    if not mincount is None:\n",
    "        # rebuild dict with restrictions\n",
    "        measurelist = {k:v for k,v in measurelist.items() if v >= mincount}\n",
    "\n",
    "    return measurelist\n",
    "\n",
    "\n",
    "def SmoothTrajectories3(traj):\n",
    "    if len(traj) > 3:\n",
    "        newtraj       = np.zeros(len(traj))\n",
    "        newtraj[0]    = (             2 * traj[0]    + traj[1] )/3.\n",
    "        newtraj[1:-1] = (traj[0:-2] + 2 * traj[1:-1] + traj[2:])/4.\n",
    "        newtraj[-1]   = (traj[-2]   + 2 * traj[-1]             )/3.\n",
    "        return newtraj\n",
    "    else:\n",
    "        return traj\n",
    "\n",
    "\n",
    "def GetCountryTrajectories(countrylist = None, data = 'Confirmed', startcases = None, maxlen = None, smooth = False):\n",
    "    if countrylist is None:\n",
    "        countrylist = jhu_data.countrylist\n",
    "    \n",
    "    trajectories = {}\n",
    "    for country in [c for c in countrylist if c in jhu_data.countrylist]:\n",
    "        ctraj = np.array(jhu_data.CountryData(country)[data], dtype = np.float)\n",
    "        starttraj = 0\n",
    "        if not startcases is None:\n",
    "            starttraj = np.argmax(ctraj >= startcases)\n",
    "            ctraj = ctraj[starttraj:]\n",
    "            if not maxlen is None:\n",
    "                ctraj = ctraj[:min(maxlen,len(ctraj))]\n",
    "        trajectories[country] = {}\n",
    "        if smooth:\n",
    "            ctraj = SmoothTrajectories3(ctraj)\n",
    "        trajectories[country]['traj'] = ctraj\n",
    "        trajectories[country]['startdate'] = ConvertDateFormat(jhu_data.CountryData(country)['Date'][starttraj])\n",
    "    \n",
    "    return trajectories\n",
    "\n",
    "        \n",
    "def GetRegressionDF(countrylist = None, measure_level = 2, shiftdays = 0, verbose = False, maxlen = None, smooth = None):\n",
    "    # construct pd.DataFrame used for regression\n",
    "    \n",
    "    # get trajectories and measure list for all countries in 'countrylist'\n",
    "    trajectories         = GetCountryTrajectories(countrylist = countrylist, data = 'Confirmed', startcases = 30, maxlen = maxlen, smooth = smooth)\n",
    "    measureIDs           = measure_data.MeasureList(countrylist = countrylist, measure_level = 2, mincount = 5)\n",
    "    cleaned_measurelist  = {CleanUpMeasureName(mn):count for mn,count in measureIDs.items()}\n",
    "    regressionDF         = None\n",
    "    \n",
    "    if verbose:\n",
    "        print(measureIDs)\n",
    "    \n",
    "    for country in trajectories.keys():\n",
    "        if country in measure_data.countrylist:\n",
    "\n",
    "            # ********************************************\n",
    "            # change observable to regress here:\n",
    "            observable                  = np.diff(np.log(trajectories[country]['traj']))\n",
    "            obslen                      = len(observable)\n",
    "            # ********************************************\n",
    "            \n",
    "            DF_country = measure_data.ImplementationTable(country           = country,\n",
    "                                                        measure_level     = 2,\n",
    "                                                        startdate         = trajectories[country]['startdate'],\n",
    "                                                        shiftdays         = shiftdays,\n",
    "                                                        maxlen            = obslen,\n",
    "                                                        clean_measurename = True)\n",
    "            \n",
    "            for measurename in DF_country.columns:\n",
    "                if measurename not in measureIDs.keys():\n",
    "                    DF_country.drop(labels = measurename, axis = 'columns')\n",
    "            \n",
    "            DF_country['Country']    = country\n",
    "            DF_country['Observable'] = observable\n",
    "\n",
    "            \n",
    "            if not (np.isnan(DF_country['Observable']).any() or np.isinf(DF_country['Observable']).any()):\n",
    "\n",
    "                if regressionDF is None:\n",
    "                    regressionDF = DF_country\n",
    "                else:\n",
    "                    regressionDF = pd.concat([regressionDF,DF_country], ignore_index = True, sort = False)\n",
    "    \n",
    "    # not implemented measures should be NaN values, set them to 0\n",
    "    regressionDF.fillna(0, inplace = True)\n",
    "    \n",
    "    return regressionDF, cleaned_measurelist\n",
    "\n",
    "\n",
    "\n",
    "def GetCountryMasks(regrDF):\n",
    "    countrylist = list(regrDF['Country'].unique())\n",
    "    maskdict = {}\n",
    "    for country in countrylist:\n",
    "        mask = list(regrDF['Country'] == country)\n",
    "        maskdict[country] = mask\n",
    "    return maskdict\n",
    "\n",
    "\n",
    "\n",
    "def CrossValidation(data = None, drop_cols = None, outputheader = None, alpha = 1e-5, alphacountry = None, crossvalcount = 10):\n",
    "    # output df\n",
    "    result_DF = None\n",
    "    \n",
    "    # assign samples to each of the crossvalidation chunks\n",
    "    datalen = len(data)\n",
    "    chunklen   = np.ones(crossvalcount,dtype = np.int) * (datalen // crossvalcount)\n",
    "    chunklen[:datalen%crossvalcount] += 1\n",
    "    samples    = np.random.permutation(\n",
    "                    np.concatenate(\n",
    "                        [i*np.ones(chunklen[i],dtype = np.int) for i in range(crossvalcount)]\n",
    "                    ))\n",
    "    \n",
    "    # generate formula of model directly from columns in DataFrame\n",
    "    measurelist = list(data.columns)\n",
    "    measurelist.remove('Observable')\n",
    "    measurelist.remove('Country')\n",
    "    formula = 'Observable ~ C(Country) + ' + ' + '.join(measurelist)\n",
    "    \n",
    "    # iterate over all chunks\n",
    "    for xv_index in range(crossvalcount):\n",
    "        # generate training and test models\n",
    "        trainidx = (samples != xv_index)\n",
    "        testidx  = (samples == xv_index)\n",
    "        trainmodel = smf.ols(formula = formula, data = data[trainidx], drop_cols = drop_cols)\n",
    "        testmodel  = smf.ols(formula = formula, data = data[testidx],  drop_cols = drop_cols)\n",
    "    \n",
    "        # if no alphacountry value is given, assume same penalty (alpha) for all paramters\n",
    "        if alphacountry is None:\n",
    "            results = trainmodel.fit_regularized(alpha = alpha, L1_wt = 1)\n",
    "        else:\n",
    "            # otherwise, penalize measures and countries differently\n",
    "            # no penality for the 'Intercept'\n",
    "            alphavec = np.zeros(len(trainmodel.exog_names))\n",
    "            for i,exogname in enumerate(trainmodel.exog_names):\n",
    "                if exogname[:10] == 'C(Country)': alphavec[i] = alphacountry\n",
    "                elif exogname == 'Intercept':     alphavec[i] = 0\n",
    "                else:                             alphavec[i] = alpha\n",
    "            results = trainmodel.fit_regularized(alpha = alphavec, L1_wt = 1)\n",
    "\n",
    "        # generate list of test params\n",
    "        # random sampling could have discarded some of these parameters in the test case\n",
    "        test_params = []\n",
    "        for paramname in testmodel.exog_names:\n",
    "            if paramname in results.params.keys():\n",
    "                test_params.append(results.params[paramname])\n",
    "            else:\n",
    "                test_params.append(0)\n",
    "\n",
    "        obs_train   = np.array(trainmodel.endog)\n",
    "        obs_test    = np.array(testmodel.endog)\n",
    "        pred_train  = trainmodel.predict(results.params)\n",
    "        pred_test   = testmodel.predict(test_params)\n",
    "            \n",
    "        # store results first in dict\n",
    "        result_dict = {}\n",
    "        if outputheader is not None:\n",
    "            result_dict.update(outputheader)\n",
    "        \n",
    "        result_dict['Iteration']        = xv_index\n",
    "        \n",
    "        result_dict['Loglike Training'] = trainmodel.loglike(results.params)\n",
    "        result_dict['Loglike Test']     = testmodel.loglike(np.array(test_params))\n",
    "\n",
    "        result_dict['R2 Training']      = 1 - np.sum((obs_train - pred_train)**2)/np.sum((obs_train - np.mean(obs_train))**2)\n",
    "        result_dict['R2 Test']          = 1 - np.sum((obs_test - pred_test)**2)/np.sum((obs_test - np.mean(obs_test))**2)\n",
    "\n",
    "        result_dict['RSS Training']     = np.sum((obs_train - pred_train)**2)\n",
    "        result_dict['RSS Test']         = np.sum((obs_test - pred_test)**2)\n",
    "\n",
    "        result_dict.update({k:v for k,v in results.params.items()})\n",
    "        \n",
    "        # append dict to df\n",
    "        if result_DF is None:\n",
    "            result_DF = pd.DataFrame({k:np.array([v]) for k,v in result_dict.items()})\n",
    "        else:\n",
    "            result_DF = result_DF.append(result_dict, ignore_index = True)\n",
    "    return result_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shiftdays = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/usr/lib64/python3.7/site-packages/numpy/lib/function_base.py:1273: RuntimeWarning: invalid value encountered in subtract\n",
      "  a = op(a[slice1], a[slice2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shiftdays = 1\n",
      "shiftdays = 2\n",
      "shiftdays = 3\n",
      "shiftdays = 4\n",
      "shiftdays = 5\n",
      "shiftdays = 6\n",
      "shiftdays = 7\n",
      "shiftdays = 8\n",
      "shiftdays = 9\n",
      "shiftdays = 10\n"
     ]
    }
   ],
   "source": [
    "# setup all dataframes with different shifts in the effect of measures\n",
    "\n",
    "maxshift           = 10\n",
    "regrDF             = {}\n",
    "\n",
    "for shiftdays in range(0, maxshift + 1):\n",
    "    print('shiftdays = {}'.format(shiftdays))\n",
    "    \n",
    "    regrDF[shiftdays], measurelist = GetRegressionDF( countrylist = measure_data.countrylist,\n",
    "                                                      shiftdays   = shiftdays,\n",
    "                                                      smooth      = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repetition = 0\n",
      "  shiftdays = 5\n",
      "     alpha = 0.000001, time = 14:39:29\n",
      "     alpha = 0.000002, time = 14:40:17\n",
      "     alpha = 0.000003, time = 14:41:09\n",
      "     alpha = 0.000004, time = 14:42:05\n",
      "     alpha = 0.000006, time = 14:42:57\n",
      "     alpha = 0.000010, time = 14:43:47\n",
      "     alpha = 0.000016, time = 14:44:39\n",
      "     alpha = 0.000025, time = 14:45:34\n",
      "     alpha = 0.000040, time = 14:46:29\n",
      "     alpha = 0.000063, time = 14:47:18\n",
      "     alpha = 0.000100, time = 14:48:05\n",
      "     alpha = 0.000158, time = 14:48:49\n",
      "     alpha = 0.000251, time = 14:49:27\n",
      "     alpha = 0.000398, time = 14:50:05\n",
      "  shiftdays = 6\n",
      "     alpha = 0.000001, time = 14:50:35\n",
      "     alpha = 0.000002, time = 14:51:36\n",
      "     alpha = 0.000003, time = 14:52:51\n",
      "     alpha = 0.000004, time = 14:54:03\n",
      "     alpha = 0.000006, time = 14:55:49\n",
      "     alpha = 0.000010, time = 14:58:21\n",
      "     alpha = 0.000016, time = 15:01:12\n",
      "     alpha = 0.000025, time = 15:03:34\n",
      "     alpha = 0.000040, time = 15:05:25\n",
      "     alpha = 0.000063, time = 15:06:01\n",
      "     alpha = 0.000100, time = 15:06:30\n",
      "     alpha = 0.000158, time = 15:06:55\n",
      "     alpha = 0.000251, time = 15:07:23\n",
      "     alpha = 0.000398, time = 15:07:53\n",
      "  shiftdays = 7\n",
      "     alpha = 0.000001, time = 15:08:15\n",
      "     alpha = 0.000002, time = 15:09:02\n",
      "     alpha = 0.000003, time = 15:09:52\n",
      "     alpha = 0.000004, time = 15:10:31\n",
      "     alpha = 0.000006, time = 15:11:16\n",
      "     alpha = 0.000010, time = 15:12:01\n",
      "     alpha = 0.000016, time = 15:12:51\n",
      "     alpha = 0.000025, time = 15:13:31\n",
      "     alpha = 0.000040, time = 15:14:10\n",
      "     alpha = 0.000063, time = 15:14:51\n",
      "     alpha = 0.000100, time = 15:15:24\n",
      "     alpha = 0.000158, time = 15:15:53\n",
      "     alpha = 0.000251, time = 15:16:24\n",
      "     alpha = 0.000398, time = 15:16:50\n",
      "  shiftdays = 8\n",
      "     alpha = 0.000001, time = 15:17:17\n",
      "     alpha = 0.000002, time = 15:18:09\n",
      "     alpha = 0.000003, time = 15:18:49\n",
      "     alpha = 0.000004, time = 15:19:30\n",
      "     alpha = 0.000006, time = 15:20:12\n",
      "     alpha = 0.000010, time = 15:21:08\n",
      "     alpha = 0.000016, time = 15:21:52\n",
      "     alpha = 0.000025, time = 15:22:28\n",
      "     alpha = 0.000040, time = 15:22:58\n",
      "     alpha = 0.000063, time = 15:23:27\n",
      "     alpha = 0.000100, time = 15:23:54\n",
      "     alpha = 0.000158, time = 15:24:18\n",
      "     alpha = 0.000251, time = 15:24:42\n",
      "     alpha = 0.000398, time = 15:25:02\n",
      "  shiftdays = 9\n",
      "     alpha = 0.000001, time = 15:25:19\n",
      "     alpha = 0.000002, time = 15:25:52\n",
      "     alpha = 0.000003, time = 15:26:25\n",
      "     alpha = 0.000004, time = 15:26:57\n",
      "     alpha = 0.000006, time = 15:27:30\n",
      "     alpha = 0.000010, time = 15:28:04\n",
      "     alpha = 0.000016, time = 15:28:36\n",
      "     alpha = 0.000025, time = 15:29:12\n",
      "     alpha = 0.000040, time = 15:29:42\n",
      "     alpha = 0.000063, time = 15:30:08\n",
      "     alpha = 0.000100, time = 15:30:32\n",
      "     alpha = 0.000158, time = 15:30:57\n",
      "     alpha = 0.000251, time = 15:31:27\n",
      "     alpha = 0.000398, time = 15:31:48\n",
      "repetition = 1\n",
      "  shiftdays = 5\n",
      "     alpha = 0.000001, time = 15:32:10\n",
      "     alpha = 0.000002, time = 15:32:58\n",
      "     alpha = 0.000003, time = 15:33:33\n",
      "     alpha = 0.000004, time = 15:34:06\n",
      "     alpha = 0.000006, time = 15:34:37\n",
      "     alpha = 0.000010, time = 15:35:07\n",
      "     alpha = 0.000016, time = 15:35:37\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9ef29f3e885b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             resultDF = CrossValidation( data         = regrDF[shiftdays],\n\u001b[1;32m     12\u001b[0m                                         \u001b[0moutputheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'shiftdays'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mshiftdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alpha'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                         alpha        = alpha)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mallres_smallshift\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a802a00856fa>\u001b[0m in \u001b[0;36mCrossValidation\u001b[0;34m(data, drop_cols, outputheader, alpha, alphacountry, crossvalcount)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# if no alphacountry value is given, assume same penalty (alpha) for all paramters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malphacountry\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_regularized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1_wt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;31m# otherwise, penalize measures and countries differently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mfit_regularized\u001b[0;34m(self, method, alpha, L1_wt, start_params, profile_scale, refit, **kwargs)\u001b[0m\n\u001b[1;32m   1067\u001b[0m                               \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                               \u001b[0mcheck_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m                               **defaults)\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sqrt_lasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_tol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.7/site-packages/statsmodels/base/elastic_net.py\u001b[0m in \u001b[0;36mfit_elasticnet\u001b[0;34m(model, method, maxiter, alpha, L1_wt, start_params, cnvrg_tol, zero_tol, refit, check_step, loglike_kwds, score_kwds, hess_kwds)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mparams0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mparams0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_offset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0moffset\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for repetition in range(3):\n",
    "    print('repetition = {}'.format(repetition))\n",
    "    allres_smallshift = None\n",
    "\n",
    "    for shiftdays in np.arange(5,10):\n",
    "        print('  shiftdays = {}'.format(shiftdays))\n",
    "\n",
    "        for alpha in np.power(10,np.linspace(-6, -3.4, num = 14, endpoint = True)):\n",
    "            print('     alpha = {:.6f}, time = {}'.format(alpha, datetime.datetime.now().strftime('%H:%M:%S')))\n",
    "            \n",
    "            resultDF = CrossValidation( data         = regrDF[shiftdays],\n",
    "                                        outputheader = {'shiftdays':shiftdays, 'alpha':alpha},\n",
    "                                        alpha        = alpha)\n",
    "\n",
    "            if allres_smallshift is None:\n",
    "                allres_smallshift = resultDF\n",
    "            else:\n",
    "                allres_smallshift = pd.concat([allres_smallshift, resultDF])\n",
    "    # store results in csv\n",
    "    allres_smallshift.to_csv('data/results_largeshift_200413_{}.csv'.format(repetition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001 0.000001\n",
      "0.000001 0.000010\n",
      "0.000001 0.000100\n",
      "0.000001 0.001000\n",
      "0.000010 0.000001\n",
      "0.000010 0.000010\n",
      "0.000010 0.000100\n",
      "0.000010 0.001000\n",
      "0.000100 0.000001\n",
      "0.000100 0.000010\n",
      "0.000100 0.000100\n",
      "0.000100 0.001000\n",
      "0.001000 0.000001\n",
      "0.001000 0.000010\n",
      "0.001000 0.000100\n",
      "0.001000 0.001000\n"
     ]
    }
   ],
   "source": [
    "allres_doublealpha = None\n",
    "#for repetition in range(10):\n",
    "for alpham in np.power(10.,np.linspace(-6,-3,num=4)):\n",
    "    for alphac in np.power(10.,np.linspace(-6,-3,num=4)):\n",
    "        print('{:.6f} {:.6f}'.format(alpham,alphac))\n",
    "        result_df = CrossValidation( data         = regrDF40[7],\n",
    "                                     outputheader = {'shiftdays':shiftdays, 'alpha':alpham, 'alphacountry':alphac},\n",
    "                                     alpha        = alpham,\n",
    "                                     alphacountry = alphac)\n",
    "        #print(result_df)\n",
    "        if allres_doublealpha is None:\n",
    "            allres_doublealpha = result_df\n",
    "        else:\n",
    "            allres_doublealpha = pd.concat([allres_doublealpha, result_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "allres_doublealpha.to_csv('results_doublealpha_200412_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
