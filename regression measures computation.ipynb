{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# statistics\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = [15,12]\n",
    "\n",
    "# own data wrappers\n",
    "from imp import reload\n",
    "import measureclass as mc; reload(mc);\n",
    "import coronadataclass as cdc; reload(cdc);\n",
    "\n",
    "np.seterr(divide = 'ignore');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into datawrapper classes\n",
    "measure_data = mc.COVID19_measures(download_data = False, measure_level = 2, only_first_dates = True, expand_measure_names = True)\n",
    "jhu_data     = cdc.CoronaData(download_data = False)\n",
    "\n",
    "# remove and rename countries to match the JFU database and the measures database\n",
    "measure_data.RemoveCountry('Diamond Princess')\n",
    "measure_data.RenameCountry('France (metropole)', 'France')\n",
    "measure_data.RenameCountry('South Korea', 'Korea, South')\n",
    "measure_data.RenameCountry('Czech Republic', 'Czechia')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def date2vector(implementdate, start = '22/1/20', end = None, shiftdays = 0):\n",
    "    # generate vector of 0s and 1s when measure is implemented or not\n",
    "    starttime     = datetime.datetime.strptime(start,         '%d/%m/%y')\n",
    "    if end is None:\n",
    "        endtime   = datetime.datetime.today()\n",
    "    else:\n",
    "        endtime   = datetime.datetime.strptime(end,           '%d/%m/%y')\n",
    "    implementtime = datetime.datetime.strptime(implementdate, '%d/%m/%Y')\n",
    "    \n",
    "    totaldays   = (endtime       - starttime).days\n",
    "    measuredays = (implementtime - starttime).days\n",
    "    \n",
    "    vec         = np.zeros(totaldays)\n",
    "    vec[min(measuredays+shiftdays,len(vec)-1):] = 1\n",
    "    \n",
    "    return vec\n",
    "\n",
    "\n",
    "def ConvertDateFormat(date):\n",
    "    m,d,y = date.split('/')\n",
    "    return '{:02d}/{:02d}/{:02d}'.format(int(d),int(m),int(y))\n",
    "\n",
    "\n",
    "def CleanUpMeasureName(measurename):\n",
    "    # regression model formula can't contain special characters\n",
    "    return ''.join([mn.capitalize() for mn in measurename.replace(',','').replace('-','').replace('/','').split(' ')])\n",
    "\n",
    "\n",
    "def GetMeasureIDs(countrylist = None, measure_level = 2, mincount = None, extend_measure_names = False):\n",
    "    if countrylist is None:\n",
    "        countrylist = measure_data.countrylist # use ALL countries\n",
    "    \n",
    "    measurelist = {}\n",
    "    \n",
    "    # get all restrictions from countries\n",
    "    for country in countrylist:\n",
    "        country_measures = measure_data.CountryData(country, measure_level = 2, extend_measure_names = extend_measure_names)\n",
    "        for measurename, initialdata in country_measures.items():\n",
    "            if not measurename in measurelist.keys():\n",
    "                measurelist[measurename] = 0\n",
    "            measurelist[measurename] += 1\n",
    "    \n",
    "    if not mincount is None:\n",
    "        # rebuild dict with restrictions\n",
    "        measurelist = {k:v for k,v in measurelist.items() if v >= mincount}\n",
    "\n",
    "    return measurelist\n",
    "\n",
    "\n",
    "def SmoothTrajectories3(traj):\n",
    "    if len(traj) > 3:\n",
    "        newtraj       = np.zeros(len(traj))\n",
    "        newtraj[0]    = (             2 * traj[0]    + traj[1] )/3.\n",
    "        newtraj[1:-1] = (traj[0:-2] + 2 * traj[1:-1] + traj[2:])/4.\n",
    "        newtraj[-1]   = (traj[-2]   + 2 * traj[-1]             )/3.\n",
    "        return newtraj\n",
    "    else:\n",
    "        return traj\n",
    "\n",
    "\n",
    "def GetCountryTrajectories(countrylist = None, data = 'Confirmed', startcases = None, maxlen = None, smooth = False):\n",
    "    if countrylist is None:\n",
    "        countrylist = jhu_data.countrylist\n",
    "    \n",
    "    trajectories = {}\n",
    "    for country in [c for c in countrylist if c in jhu_data.countrylist]:\n",
    "        ctraj = np.array(jhu_data.CountryData(country)[data], dtype = np.float)\n",
    "        starttraj = 0\n",
    "        if not startcases is None:\n",
    "            starttraj = np.argmax(ctraj >= startcases)\n",
    "            ctraj = ctraj[starttraj:]\n",
    "            if not maxlen is None:\n",
    "                ctraj = ctraj[:min(maxlen,len(ctraj))]\n",
    "        trajectories[country] = {}\n",
    "        if smooth:\n",
    "            ctraj = SmoothTrajectories3(ctraj)\n",
    "        trajectories[country]['traj'] = ctraj\n",
    "        trajectories[country]['startdate'] = ConvertDateFormat(jhu_data.CountryData(country)['Date'][starttraj])\n",
    "    \n",
    "    return trajectories\n",
    "\n",
    "        \n",
    "def GetRegressionDF(countrylist = None, measure_level = 2, shiftdays = 0, verbose = False, maxlen = None, smooth = None):\n",
    "    # construct pd.DataFrame used for regression\n",
    "    \n",
    "    # get trajectories and measure list for all countries in 'countrylist'\n",
    "    trajectories         = GetCountryTrajectories(countrylist = countrylist, data = 'Confirmed', startcases = 30, maxlen = maxlen, smooth = smooth)\n",
    "    measureIDs           = measure_data.MeasureList(countrylist = countrylist, measure_level = 2, mincount = 5)\n",
    "    cleaned_measurelist  = {CleanUpMeasureName(mn):count for mn,count in measureIDs.items()}\n",
    "    regressionDF         = None\n",
    "    \n",
    "    if verbose:\n",
    "        print(measureIDs)\n",
    "    \n",
    "    for country in trajectories.keys():\n",
    "        if country in measure_data.countrylist:\n",
    "\n",
    "            # ********************************************\n",
    "            # change observable to regress here:\n",
    "            observable                  = np.diff(np.log(trajectories[country]['traj']))\n",
    "            obslen                      = len(observable)\n",
    "            # ********************************************\n",
    "            \n",
    "            DF_country = measure_data.ImplementationTable(country           = country,\n",
    "                                                        measure_level     = 2,\n",
    "                                                        startdate         = trajectories[country]['startdate'],\n",
    "                                                        shiftdays         = shiftdays,\n",
    "                                                        maxlen            = obslen,\n",
    "                                                        clean_measurename = True)\n",
    "            \n",
    "            for measurename in DF_country.columns:\n",
    "                if measurename not in measureIDs.keys():\n",
    "                    DF_country.drop(labels = measurename, axis = 'columns')\n",
    "            \n",
    "            DF_country['Country']    = country\n",
    "            DF_country['Observable'] = observable\n",
    "\n",
    "            \n",
    "            if not (np.isnan(DF_country['Observable']).any() or np.isinf(DF_country['Observable']).any()):\n",
    "\n",
    "                if regressionDF is None:\n",
    "                    regressionDF = DF_country\n",
    "                else:\n",
    "                    regressionDF = pd.concat([regressionDF,DF_country], ignore_index = True, sort = False)\n",
    "    \n",
    "    # not implemented measures should be NaN values, set them to 0\n",
    "    regressionDF.fillna(0, inplace = True)\n",
    "    \n",
    "    return regressionDF, cleaned_measurelist\n",
    "\n",
    "\n",
    "\n",
    "def GetCountryMasks(regrDF):\n",
    "    countrylist = list(regrDF['Country'].unique())\n",
    "    maskdict = {}\n",
    "    for country in countrylist:\n",
    "        mask = list(regrDF['Country'] == country)\n",
    "        maskdict[country] = mask\n",
    "    return maskdict\n",
    "\n",
    "\n",
    "\n",
    "def CrossValidation(data = None, drop_cols = None, outputheader = None, alpha = 1e-5, alphacountry = None, crossvalcount = 10):\n",
    "    # output df\n",
    "    result_DF = None\n",
    "    \n",
    "    # assign samples to each of the crossvalidation chunks\n",
    "    datalen = len(data)\n",
    "    chunklen   = np.ones(crossvalcount,dtype = np.int) * (datalen // crossvalcount)\n",
    "    chunklen[:datalen%crossvalcount] += 1\n",
    "    samples    = np.random.permutation(\n",
    "                    np.concatenate(\n",
    "                        [i*np.ones(chunklen[i],dtype = np.int) for i in range(crossvalcount)]\n",
    "                    ))\n",
    "    \n",
    "    # generate formula of model directly from columns in DataFrame\n",
    "    measurelist = list(data.columns)\n",
    "    measurelist.remove('Observable')\n",
    "    measurelist.remove('Country')\n",
    "    formula = 'Observable ~ C(Country) + ' + ' + '.join(measurelist)\n",
    "    \n",
    "    # iterate over all chunks\n",
    "    for xv_index in range(crossvalcount):\n",
    "        # generate training and test models\n",
    "        trainidx = (samples != xv_index)\n",
    "        testidx  = (samples == xv_index)\n",
    "        trainmodel = smf.ols(formula = formula, data = data[trainidx], drop_cols = drop_cols)\n",
    "        testmodel  = smf.ols(formula = formula, data = data[testidx],  drop_cols = drop_cols)\n",
    "    \n",
    "        # if no alphacountry value is given, assume same penalty (alpha) for all paramters\n",
    "        if alphacountry is None:\n",
    "            results = trainmodel.fit_regularized(alpha = alpha, L1_wt = 1)\n",
    "        else:\n",
    "            # otherwise, penalize measures and countries differently\n",
    "            # no penality for the 'Intercept'\n",
    "            alphavec = np.zeros(len(trainmodel.exog_names))\n",
    "            for i,exogname in enumerate(trainmodel.exog_names):\n",
    "                if exogname[:10] == 'C(Country)': alphavec[i] = alphacountry\n",
    "                elif exogname == 'Intercept':     alphavec[i] = 0\n",
    "                else:                             alphavec[i] = alpha\n",
    "            results = trainmodel.fit_regularized(alpha = alphavec, L1_wt = 1)\n",
    "\n",
    "        # generate list of test params\n",
    "        # random sampling could have discarded some of these parameters in the test case\n",
    "        test_params = []\n",
    "        for paramname in testmodel.exog_names:\n",
    "            if paramname in results.params.keys():\n",
    "                test_params.append(results.params[paramname])\n",
    "            else:\n",
    "                test_params.append(0)\n",
    "\n",
    "        obs_train   = np.array(trainmodel.endog)\n",
    "        obs_test    = np.array(testmodel.endog)\n",
    "        pred_train  = trainmodel.predict(results.params)\n",
    "        pred_test   = testmodel.predict(test_params)\n",
    "            \n",
    "        # store results first in dict\n",
    "        result_dict = {}\n",
    "        if outputheader is not None:\n",
    "            result_dict.update(outputheader)\n",
    "        \n",
    "        result_dict['Iteration']        = xv_index\n",
    "        \n",
    "        result_dict['Loglike Training'] = trainmodel.loglike(results.params)\n",
    "        result_dict['Loglike Test']     = testmodel.loglike(np.array(test_params))\n",
    "\n",
    "        result_dict['R2 Training']      = 1 - np.sum((obs_train - pred_train)**2)/np.sum((obs_train - np.mean(obs_train))**2)\n",
    "        result_dict['R2 Test']          = 1 - np.sum((obs_test - pred_test)**2)/np.sum((obs_test - np.mean(obs_test))**2)\n",
    "\n",
    "        result_dict['RSS Training']     = np.sum((obs_train - pred_train)**2)\n",
    "        result_dict['RSS Test']         = np.sum((obs_test - pred_test)**2)\n",
    "\n",
    "        result_dict.update({k:v for k,v in results.params.items()})\n",
    "        \n",
    "        # append dict to df\n",
    "        if result_DF is None:\n",
    "            result_DF = pd.DataFrame({k:np.array([v]) for k,v in result_dict.items()})\n",
    "        else:\n",
    "            result_DF = result_DF.append(result_dict, ignore_index = True)\n",
    "    return result_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shiftdays = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/usr/lib64/python3.7/site-packages/numpy/lib/function_base.py:1273: RuntimeWarning: invalid value encountered in subtract\n",
      "  a = op(a[slice1], a[slice2])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shiftdays = 1\n",
      "shiftdays = 2\n",
      "shiftdays = 3\n",
      "shiftdays = 4\n",
      "shiftdays = 5\n",
      "shiftdays = 6\n",
      "shiftdays = 7\n",
      "shiftdays = 8\n",
      "shiftdays = 9\n",
      "shiftdays = 10\n"
     ]
    }
   ],
   "source": [
    "# setup all dataframes with different shifts in the effect of measures\n",
    "\n",
    "maxshift           = 10\n",
    "regrDF             = {}\n",
    "\n",
    "for shiftdays in range(0, maxshift + 1):\n",
    "    print('shiftdays = {}'.format(shiftdays))\n",
    "    \n",
    "    regrDF[shiftdays], measurelist = GetRegressionDF( countrylist = measure_data.countrylist,\n",
    "                                                      shiftdays   = shiftdays,\n",
    "                                                      smooth      = True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repetition = 0\n",
      "  shiftdays = 0\n",
      "     alpha = 0.000001, time = 12:17:18\n",
      "     alpha = 0.000002, time = 12:17:41\n",
      "     alpha = 0.000003, time = 12:18:10\n",
      "     alpha = 0.000004, time = 12:18:43\n",
      "     alpha = 0.000006, time = 12:19:12\n",
      "     alpha = 0.000010, time = 12:19:40\n",
      "     alpha = 0.000016, time = 12:20:08\n",
      "     alpha = 0.000025, time = 12:20:35\n",
      "     alpha = 0.000040, time = 12:21:00\n",
      "     alpha = 0.000063, time = 12:21:26\n",
      "     alpha = 0.000100, time = 12:21:52\n",
      "     alpha = 0.000158, time = 12:22:13\n",
      "     alpha = 0.000251, time = 12:22:33\n",
      "     alpha = 0.000398, time = 12:22:51\n",
      "  shiftdays = 1\n",
      "     alpha = 0.000001, time = 12:23:07\n",
      "     alpha = 0.000002, time = 12:23:38\n",
      "     alpha = 0.000003, time = 12:24:08\n",
      "     alpha = 0.000004, time = 12:24:39\n",
      "     alpha = 0.000006, time = 12:25:09\n",
      "     alpha = 0.000010, time = 12:25:39\n",
      "     alpha = 0.000016, time = 12:26:07\n",
      "     alpha = 0.000025, time = 12:26:36\n",
      "     alpha = 0.000040, time = 12:27:05\n",
      "     alpha = 0.000063, time = 12:27:30\n",
      "     alpha = 0.000100, time = 12:27:54\n",
      "     alpha = 0.000158, time = 12:28:16\n",
      "     alpha = 0.000251, time = 12:28:37\n",
      "     alpha = 0.000398, time = 12:28:55\n",
      "  shiftdays = 2\n",
      "     alpha = 0.000001, time = 12:29:12\n",
      "     alpha = 0.000002, time = 12:29:42\n",
      "     alpha = 0.000003, time = 12:30:12\n",
      "     alpha = 0.000004, time = 12:30:42\n",
      "     alpha = 0.000006, time = 12:31:13\n",
      "     alpha = 0.000010, time = 12:31:43\n",
      "     alpha = 0.000016, time = 12:32:12\n",
      "     alpha = 0.000025, time = 12:32:44\n",
      "     alpha = 0.000040, time = 12:33:12\n",
      "     alpha = 0.000063, time = 12:33:39\n",
      "     alpha = 0.000100, time = 12:34:05\n",
      "     alpha = 0.000158, time = 12:34:28\n",
      "     alpha = 0.000251, time = 12:34:48\n",
      "     alpha = 0.000398, time = 12:35:10\n",
      "  shiftdays = 3\n",
      "     alpha = 0.000001, time = 12:35:27\n",
      "     alpha = 0.000002, time = 12:35:58\n",
      "     alpha = 0.000003, time = 12:36:28\n",
      "     alpha = 0.000004, time = 12:36:59\n"
     ]
    }
   ],
   "source": [
    "for repetition in range(3):\n",
    "    print('repetition = {}'.format(repetition))\n",
    "    allres_smallshift = None\n",
    "\n",
    "    for shiftdays in np.arange(0,5):\n",
    "        print('  shiftdays = {}'.format(shiftdays))\n",
    "\n",
    "        for alpha in np.power(10,np.linspace(-6, -3.4, num = 14, endpoint = True)):\n",
    "            print('     alpha = {:.6f}, time = {}'.format(alpha, datetime.datetime.now().strftime('%H:%M:%S')))\n",
    "            \n",
    "            resultDF = CrossValidation( data         = regrDF[shiftdays],\n",
    "                                        outputheader = {'shiftdays':shiftdays, 'alpha':alpha},\n",
    "                                        alpha        = alpha)\n",
    "\n",
    "            if allres_smallshift is None:\n",
    "                allres_smallshift = resultDF\n",
    "            else:\n",
    "                allres_smallshift = pd.concat([allres_smallshift, resultDF])\n",
    "    # store results in csv\n",
    "    allres_smallshift.to_csv('data/results_smallshift_200413_{}.csv'.format(repetition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repetition = 0\n",
      "generating DF and model for shiftdays = 5\n",
      "generating DF and model for shiftdays = 6\n",
      "generating DF and model for shiftdays = 7\n",
      "generating DF and model for shiftdays = 8\n",
      "generating DF and model for shiftdays = 9\n",
      "model estimates, s = 5\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 6\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 7\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 8\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 9\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "repetition = 1\n",
      "generating DF and model for shiftdays = 5\n",
      "generating DF and model for shiftdays = 6\n",
      "generating DF and model for shiftdays = 7\n",
      "generating DF and model for shiftdays = 8\n",
      "generating DF and model for shiftdays = 9\n",
      "model estimates, s = 5\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 6\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 7\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 8\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 9\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "repetition = 2\n",
      "generating DF and model for shiftdays = 5\n",
      "generating DF and model for shiftdays = 6\n",
      "generating DF and model for shiftdays = 7\n",
      "generating DF and model for shiftdays = 8\n",
      "generating DF and model for shiftdays = 9\n",
      "model estimates, s = 5\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 6\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 7\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 8\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "model estimates, s = 9\n",
      "   alpha = 0.000001\n",
      "   alpha = 0.000002\n",
      "   alpha = 0.000003\n",
      "   alpha = 0.000004\n",
      "   alpha = 0.000006\n",
      "   alpha = 0.000010\n",
      "   alpha = 0.000016\n",
      "   alpha = 0.000025\n",
      "   alpha = 0.000040\n",
      "   alpha = 0.000063\n",
      "   alpha = 0.000100\n",
      "   alpha = 0.000158\n",
      "   alpha = 0.000251\n",
      "   alpha = 0.000398\n",
      "repetition = 3\n",
      "generating DF and model for shiftdays = 5\n",
      "generating DF and model for shiftdays = 6\n",
      "generating DF and model for shiftdays = 7\n",
      "generating DF and model for shiftdays = 8\n",
      "generating DF and model for shiftdays = 9\n",
      "model estimates, s = 5\n",
      "   alpha = 0.000001\n"
     ]
    }
   ],
   "source": [
    "# cross-validation with random sampling\n",
    "# repetition 10 times\n",
    "\n",
    "samples_dict = {}\n",
    "\n",
    "for repetition in range(10):\n",
    "    \n",
    "    print('repetition = {}'.format(repetition))\n",
    "    \n",
    "    maxshift     = 10\n",
    "    regrDF40       = {}\n",
    "    model_train40  = {}\n",
    "    model_test40   = {}\n",
    "\n",
    "    regrDF_train40 = {}\n",
    "    regrDF_test40  = {}\n",
    "\n",
    "    allresults_rndXv_chunksize40 = None\n",
    "\n",
    "\n",
    "\n",
    "    for shiftdays in range(5, 10):\n",
    "        print('generating DF and model for shiftdays = {}'.format(shiftdays))\n",
    "        regrDF40[shiftdays], measurelist = GetRegressionDF( countrylist = measure_data.countrylist,\n",
    "                                                          shiftdays   = shiftdays,\n",
    "                                                          maxlen      = 40,\n",
    "                                                          smooth      = True)\n",
    "\n",
    "        countrylist = regrDF40[shiftdays]['Country'].unique()\n",
    "        formula     = 'Observable ~ C(Country) + ' + ' + '.join(measurelist)\n",
    "\n",
    "        # generate random list of samples for 10x cross validation\n",
    "        xval_count = 10\n",
    "        datalen    = len(regrDF40[shiftdays])\n",
    "        chunklen   = np.ones(xval_count,dtype = np.int) * (datalen // xval_count)\n",
    "        chunklen[:datalen%xval_count] += 1\n",
    "        samples    = np.random.permutation(np.concatenate([i*np.ones(chunklen[i],dtype = np.int) for i in range(xval_count)]))\n",
    "        \n",
    "        samples_dict[repetition] = samples\n",
    "        assert len(samples) == datalen\n",
    "\n",
    "        regrDF_train40[shiftdays] = []\n",
    "        regrDF_test40 [shiftdays] = []\n",
    "        model_train40 [shiftdays] = []\n",
    "        model_test40  [shiftdays] = []\n",
    "\n",
    "        for i in range(xval_count):\n",
    "            regrDF_train40[shiftdays].append(regrDF40[shiftdays][samples != i])\n",
    "            regrDF_test40 [shiftdays].append(regrDF40[shiftdays][samples == i])\n",
    "\n",
    "            model_train40 [shiftdays].append(smf.ols(formula = formula, data = regrDF_train40[shiftdays][i]))\n",
    "            model_test40  [shiftdays].append(smf.ols(formula = formula, data = regrDF_test40[shiftdays][i]))\n",
    "\n",
    "            \n",
    "    for shiftdays in np.arange(5,10):\n",
    "\n",
    "        print('model estimates, s = {}'.format(shiftdays))\n",
    "\n",
    "        for alpha in np.power(10,np.linspace(-6, -3.4, num = 14, endpoint = True)):\n",
    "            print('   alpha = {:.6f}'.format(alpha))\n",
    "            for i in range(xval_count):\n",
    "\n",
    "                result_dict = CrossValidationFit( trainmodel = model_train40[shiftdays][i],\n",
    "                                                  testmodel  = model_test40[shiftdays][i],\n",
    "                                                  header     = {'shiftdays':shiftdays, 'alpha':alpha, 'iteration':i},\n",
    "                                                  alpha      = alpha)\n",
    "\n",
    "\n",
    "                if allresults_rndXv_chunksize40 is None:\n",
    "                    allresults_rndXv_chunksize40 = pd.DataFrame({k:np.array([v]) for k,v in result_dict.items()})\n",
    "                else:\n",
    "                    allresults_rndXv_chunksize40 = allresults_rndXv_chunksize40.append(result_dict, ignore_index = True)\n",
    "\n",
    "    allresults_rndXv_chunksize40.to_csv('results_Xval_maxlen40_200412_{}.csv'.format(repetition))\n",
    "pd.DataFrame({'rep{}'.format(s):np.array(samp) for s,samp in samples_dict.items()}).to_csv('samplevec_Xval_maxlen40_200412.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allresults_rndXv.to_csv('results_Xval_rnd10_200411.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allresults_rndXv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating DF and model for shiftdays = 7\n"
     ]
    }
   ],
   "source": [
    "#print('repetition = {}'.format(repetition))\n",
    "\n",
    "maxshift     = 10\n",
    "regrDF40       = {}\n",
    "model_train40  = {}\n",
    "model_test40   = {}\n",
    "\n",
    "regrDF_train40 = {}\n",
    "regrDF_test40  = {}\n",
    "\n",
    "allresults_rndXv_chunksize40 = None\n",
    "\n",
    "\n",
    "\n",
    "for shiftdays in range(7, 8):\n",
    "    print('generating DF and model for shiftdays = {}'.format(shiftdays))\n",
    "    regrDF40[shiftdays], measurelist = GetRegressionDF( countrylist = measure_data.countrylist,\n",
    "                                                      shiftdays   = shiftdays,\n",
    "                                                      maxlen      = 40,\n",
    "                                                      smooth      = True)\n",
    "\n",
    "    countrylist = regrDF40[shiftdays]['Country'].unique()\n",
    "    formula     = 'Observable ~ C(Country) + ' + ' + '.join(measurelist)\n",
    "\n",
    "    # generate random list of samples for 10x cross validation\n",
    "    xval_count = 10\n",
    "    datalen    = len(regrDF40[shiftdays])\n",
    "    chunklen   = np.ones(xval_count,dtype = np.int) * (datalen // xval_count)\n",
    "    chunklen[:datalen%xval_count] += 1\n",
    "    samples    = np.random.permutation(np.concatenate([i*np.ones(chunklen[i],dtype = np.int) for i in range(xval_count)]))\n",
    "\n",
    "    #samples_dict[repetition] = samples\n",
    "    assert len(samples) == datalen\n",
    "\n",
    "    regrDF_train40[shiftdays] = []\n",
    "    regrDF_test40 [shiftdays] = []\n",
    "    model_train40 [shiftdays] = []\n",
    "    model_test40  [shiftdays] = []\n",
    "\n",
    "    for i in range(xval_count):\n",
    "        regrDF_train40[shiftdays].append(regrDF40[shiftdays][samples != i])\n",
    "        regrDF_test40 [shiftdays].append(regrDF40[shiftdays][samples == i])\n",
    "\n",
    "        model_train40 [shiftdays].append(smf.ols(formula = formula, data = regrDF_train40[shiftdays][i]))\n",
    "        model_test40  [shiftdays].append(smf.ols(formula = formula, data = regrDF_test40[shiftdays][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000001 0.000001\n",
      "0.000001 0.000010\n",
      "0.000001 0.000100\n",
      "0.000001 0.001000\n",
      "0.000010 0.000001\n",
      "0.000010 0.000010\n",
      "0.000010 0.000100\n",
      "0.000010 0.001000\n",
      "0.000100 0.000001\n",
      "0.000100 0.000010\n",
      "0.000100 0.000100\n",
      "0.000100 0.001000\n",
      "0.001000 0.000001\n",
      "0.001000 0.000010\n",
      "0.001000 0.000100\n",
      "0.001000 0.001000\n"
     ]
    }
   ],
   "source": [
    "allres_doublealpha = None\n",
    "#for repetition in range(10):\n",
    "for alpham in np.power(10.,np.linspace(-6,-3,num=4)):\n",
    "    for alphac in np.power(10.,np.linspace(-6,-3,num=4)):\n",
    "        print('{:.6f} {:.6f}'.format(alpham,alphac))\n",
    "        result_df = CrossValidation( data         = regrDF40[7],\n",
    "                                     outputheader = {'shiftdays':shiftdays, 'alpha':alpham, 'alphacountry':alphac},\n",
    "                                     alpha        = alpham,\n",
    "                                     alphacountry = alphac)\n",
    "        #print(result_df)\n",
    "        if allres_doublealpha is None:\n",
    "            allres_doublealpha = result_df\n",
    "        else:\n",
    "            allres_doublealpha = pd.concat([allres_doublealpha, result_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "allres_doublealpha.to_csv('results_doublealpha_200412_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "(allres_doublealpha.groupby(['alpha','alphacountry'],as_index = False)['Loglike Test'].mean()).to_csv('doublealpha.txt',sep = ' ', header = False, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
